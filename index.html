<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>worshop LLMs 4 CLS</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
    type='text/css'>
</head>

<body>
  <p align="center">
    <h1><strong>Workshop: <br>AI and Large Language Models (LLMs) for the Analysis of Large Literary Corpora</strong></h1>
    <h3>December 5, 2023</h3>
  </p>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <h2>Venue</h2>
              <p>The workshop will take place at the Ecole Normale Superieure, in salle Dussane, 45 rue d'Ulm, 75005 Paris, France.
              <br> is held in coordination with the <a href="https://2023.computational-humanities-research.org">CHR 2023 Conference</a> (Dec 6-8, 2023, EPITA, Paris).
              </p>
               <p>Registration is <strong>mandatory</strong> at this link:
                <a href="https://framaforms.org/chr2023-workshop-ai-and-large-language-models-llms-for-the-analysis-of-large-literary-corpora">CHR2023-Workshop registration</a>.
               </p>
                <p>The workshop will be on site. Remote attendance will be possible: a link will be sent the day before the workshop to participants who registered with the link above.</p>

            </td>
            <td width="33%">
              <img width="200" src="images/profile.png">
            </td>
          </tr>
        </table>


        <h1>Situation</h1>

        <p>
          The availability of large collections of literary texts (several thousands of novels for a given language for
          example, covering a significant part of the literature of the time) along with statistical models have profoundly
          changed our knowledge of literature. In parallel, the availability of efficient natural language processing (NLP)
          tools has made possible the structural analysis of these novels.
      </p>
      <p>
          More recently, the advent of large language models and more specifically generative AI has again dramatically
          modified the analysis of literary texts, providing more robust and more versatile annotation tools. Zero-shot
          learning means that new categories and new tasks can be explored at a reduced cost, through prompting for example.
          But this is not without raising new questions. These techniques may be less robust (depending on the quality of the
          training set), harder to evaluate and harder to replicate (since models evolve very quickly; they depend on several
          parameters and do not always produce the same output).
      </p>
      <p>
          The workshop will explore themes related to the annotation and analysis of large literary corpora. It will more
          specifically examine for what generic tasks we now have access to relatively robust and accurate tools. We will
          then investigate to what extent generative models can be exploited in this context, their benefits and their
          potential drawbacks. The implication on teaching may also be addressed, as well as the very quick obsolescence of
          current programs, given the pace of the evolution of the domain.
      </p>



      <h2>Schedule</h2>
      <ul>
          <li><strong>9:45-10:00: Introduction.</strong></li>
          <li><strong>10:00-10-45: The Promise and Peril of Large Language Models for Cultural Analytics</strong><br>David Bamman (Berkeley, USA).</li>
          <li><strong>10:45-12:00: Analyzing Large French Literary Corpora with Fr-BookNLP</strong><br>Frédérique Mélanie, Jean Barré, Olga Seminck, Thierry Poibeau (CNRS & ENS/PSL, France).</li>
          <li><strong>Lunch.</strong></li>
          <li><strong>1:30-2:15: Prediction and Surprise</strong><br>Ted Underwood (Illinois Urbana-Champaign, USA).</li>
          <li><strong>2:15-3:00: Automatic Information Extraction from Literary Works for Audiobooks Generation</strong><br>Elena Epure (Deezer, France) & Gaspard Michel (Deezer & Loria, France).</li>
          <li><strong>Break.</strong></li>
          <li><strong>3:30-4:15: Computationally Modeling Collective Narratives</strong><br>Andrew Piper (McGill, Canada).</li>
          <li><strong>4:15-5:15 Debate: LLMs, Generative Models and Literary Analysis: where are we going?</strong></li>
      </ul>
  
      <h2>Sponsors</h2>
      <p>With the support of Lattice (<a href="https://lattice.cnrs.fr">https://lattice.cnrs.fr</a>), CNRS (IRN Cyclades) and Prairie (Paris Artificial Intelligence Research Institute, <a href="https://prairie-institute.fr">https://prairie-institute.fr</a>).</p>
  
      <h2>Scientific committee</h2>
      <p>David Bamman (Berkeley, USA), Evelyn Gius (Darmstadt, Germany), Thierry Poibeau (CNRS, France), Sara Tonelli (FKB, Italy).</p>
  
      <h2>Organization committee</h2>
      <ul>
          <li>Jean Barré (<a href="mailto:jean.barre@ens.psl.eu">jean.barre@ens.psl.eu</a>),</li>
          <li>Pedro Cabrera,</li>
          <li>Florian Cafiero (<a href="mailto:florian.cafiero@sciencespo.fr">florian.cafiero@sciencespo.fr</a>),</li>
          <li>Fabien Garrido,</li>
          <li>Virginie Pauchont,</li>
          <li>Marie Puren (<a href="mailto:marie.puren1406@gmail.com">marie.puren1406@gmail.com</a>),</li>
          <li>Thierry Poibeau (<a href="mailto:thierry.poibeau@ens.psl.eu">thierry.poibeau@ens.psl.eu</a>).</li>
      </ul>





        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Big thanks to the <a href="https://github.com/jonbarron/jonbarron_website"><strong>original template author</strong></a>.
                </font>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>

</body>

</html>
